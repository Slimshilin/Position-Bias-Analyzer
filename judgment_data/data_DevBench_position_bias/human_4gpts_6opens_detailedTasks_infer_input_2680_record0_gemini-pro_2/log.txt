Reponse length
+----+------------------------------+--------------------+--------------------+
|    |            model             |        mean        |        std         |
+----+------------------------------+--------------------+--------------------+
| 0  |            human             | 458.2857142857143  | 297.2042175655916  |
| 1  |      gpt-3.5-turbo-1106      | 566.6160714285714  | 169.61059632159285 |
| 2  |          gpt-4-0613          |      619.1875      | 132.10064691430762 |
| 3  |      gpt-4-1106-preview      | 864.8839285714286  | 190.20668952933593 |
| 4  |      gpt-4-0125-preview      | 764.0803571428571  | 156.85520725410933 |
| 5  |    codellama-7b-instruct     | 1973.2232142857142 | 1210.9020892781712 |
| 6  |    codellama-13b-instruct    | 1180.3035714285713 | 1020.9330889583812 |
| 7  |    codellama-34b-instruct    | 1274.7767857142858 | 824.0602733441008  |
| 8  | deepseek-coder-1.3b-instruct | 641.5267857142857  | 708.9595364211737  |
| 9  | deepseek-coder-6.7b-instruct | 568.5178571428571  | 244.38706061370794 |
| 10 | deepseek-coder-33b-instruct  | 597.5892857142857  | 234.47039691197955 |
+----+------------------------------+--------------------+--------------------+
Total comparisons: 2240. Failed to response: 0
Total comparisons: 2240. Non exact matches:  2240
Extracted 2238 answers from the responses (extraction success rate 99.91%)
1466 out of 2238 answers are consistent. (A vs. B <-> B vs. A) The consistent rate is 65.50%
(Win + Draw / 2) w. human: 
+---+------------------------------+--------------+--------+--------------+---------------------+-----------+--------------------------------------+---------------------------+-------------------------------------+-----------------------------+-----------------------------------------+---------------------------------+---------------------------------------+----------------------------------+------------------------------------+------------------------------------------------+-----------------------------------+----------------------+------------------------+--------------------------+
|   |            model             | Overall-lang |   EN   | UML_sequence | architecture_design | uml_class | UML_sequence-cohesion_and_decoupling | UML_sequence-faithfulness | UML_sequence-interaction_complexity | UML_sequence-practicability | UML_sequence-uniformity_and_integration | architecture_design-conformance | architecture_design-design_and_coding | architecture_design-faithfulness | architecture_design-practicability | architecture_design-uniformity_and_integration | uml_class-cohesion_and_decoupling | uml_class-complexity | uml_class-faithfulness | uml_class-practicability |
+---+------------------------------+--------------+--------+--------------+---------------------+-----------+--------------------------------------+---------------------------+-------------------------------------+-----------------------------+-----------------------------------------+---------------------------------+---------------------------------------+----------------------------------+------------------------------------+------------------------------------------------+-----------------------------------+----------------------+------------------------+--------------------------+
| 5 |      gpt-4-1106-preview      |     1.0      |  1.0   |     1.0      |         1.0         |    1.0    |                 1.0                  |            1.0            |                 1.0                 |             1.0             |                   1.0                   |               1.0               |                  1.0                  |               1.0                |                1.0                 |                      1.0                       |                1.0                |         1.0          |          1.0           |           1.0            |
| 7 |      gpt-4-0125-preview      |    0.9789    | 0.9789 |     1.0      |         1.0         |  0.9231   |                 1.0                  |            1.0            |                 1.0                 |             1.0             |                   1.0                   |               1.0               |                  1.0                  |               1.0                |                1.0                 |                      1.0                       |              0.8571               |        0.8571        |          1.0           |           1.0            |
| 1 |          gpt-4-0613          |    0.9167    | 0.9167 |     1.0      |       0.8125        |  0.8571   |                 1.0                  |            1.0            |                 1.0                 |             1.0             |                   1.0                   |             0.6667              |                  1.0                  |               1.0                |                1.0                 |                      0.0                       |                1.0                |         0.75         |         0.7143         |           1.0            |
| 6 |    codellama-34b-instruct    |    0.8865    | 0.8865 |    0.8776    |       0.7895        |   0.963   |                0.8333                |          0.8462           |               0.6667                |             1.0             |                   1.0                   |              0.75               |                  0.5                  |               1.0                |                1.0                 |                      0.6                       |                1.0                |         1.0          |         0.875          |           1.0            |
| 8 |      gpt-3.5-turbo-1106      |    0.8675    | 0.8675 |    0.9375    |        0.84         |  0.8077   |                 1.0                  |           0.875           |               0.8333                |             1.0             |                   1.0                   |               1.0               |                0.7143                 |               0.75               |                0.8                 |                      1.0                       |              0.8571               |        0.5714        |         0.8571         |           1.0            |
| 2 | deepseek-coder-6.7b-instruct |    0.8067    | 0.8067 |    0.8261    |       0.8205        |  0.7647   |                 1.0                  |            0.6            |                 0.8                 |            0.75             |                   1.0                   |               1.0               |                0.8333                 |               0.5                |                0.8                 |                     0.8889                     |                0.8                |        0.8333        |          0.75          |           0.5            |
| 3 | deepseek-coder-33b-instruct  |    0.7833    | 0.7833 |    0.7826    |       0.8333        |  0.6923   |                 0.6                  |            0.5            |                 1.0                 |             1.0             |                   0.8                   |              0.75               |                0.8333                 |               1.0                |                0.8                 |                      0.8                       |              0.8333               |         0.25         |          1.0           |           1.0            |
| 0 |    codellama-13b-instruct    |    0.6912    | 0.6912 |    0.7391    |       0.5833        |  0.7619   |                 1.0                  |            0.8            |                 1.0                 |             0.6             |                   0.5                   |              0.25               |                0.3333                 |              0.8333              |                1.0                 |                     0.6667                     |                1.0                |        0.8571        |          0.4           |          0.8333          |
| 9 |    codellama-7b-instruct     |    0.6721    | 0.6721 |     0.76     |       0.4118        |  0.7895   |                 0.6                  |           0.75            |                 0.8                 |           0.8333            |                   0.8                   |              0.75               |                  0.0                  |               0.0                |                0.4                 |                     0.6667                     |              0.6667               |        0.8333        |          1.0           |          0.6667          |
| 4 | deepseek-coder-1.3b-instruct |    0.3714    | 0.3714 |    0.3793    |       0.3333        |  0.4118   |                0.1429                |            0.4            |                0.75                 |           0.4286            |                 0.3333                  |               0.0               |                0.4286                 |               0.4                |                0.25                |                      0.5                       |                0.0                |         0.4          |          0.6           |           0.4            |
+---+------------------------------+--------------+--------+--------------+---------------------+-----------+--------------------------------------+---------------------------+-------------------------------------+-----------------------------+-----------------------------------------+---------------------------------+---------------------------------------+----------------------------------+------------------------------------+------------------------------------------------+-----------------------------------+----------------------+------------------------+--------------------------+
(Win + Both Good) w. human: 
+---+------------------------------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------+---------------------------+-------------------------------------+-----------------------------+-----------------------------------------+---------------------------------+---------------------------------------+----------------------------------+------------------------------------+------------------------------------------------+-----------------------------------+----------------------+------------------------+--------------------------+
|   |            model             |    Overall-lang     |         EN          |    UML_sequence     | architecture_design |      uml_class      | UML_sequence-cohesion_and_decoupling | UML_sequence-faithfulness | UML_sequence-interaction_complexity | UML_sequence-practicability | UML_sequence-uniformity_and_integration | architecture_design-conformance | architecture_design-design_and_coding | architecture_design-faithfulness | architecture_design-practicability | architecture_design-uniformity_and_integration | uml_class-cohesion_and_decoupling | uml_class-complexity | uml_class-faithfulness | uml_class-practicability |
+---+------------------------------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------+---------------------------+-------------------------------------+-----------------------------+-----------------------------------------+---------------------------------+---------------------------------------+----------------------------------+------------------------------------+------------------------------------------------+-----------------------------------+----------------------+------------------------+--------------------------+
| 5 |      gpt-4-1106-preview      |         1.0         |         1.0         |         1.0         |         1.0         |         1.0         |                 1.0                  |            1.0            |                 1.0                 |             1.0             |                   1.0                   |               1.0               |                  1.0                  |               1.0                |                1.0                 |                      1.0                       |                1.0                |         1.0          |          1.0           |           1.0            |
| 7 |      gpt-4-0125-preview      | 0.9789000153541565  | 0.9789000153541565  |         1.0         |         1.0         | 0.9230999946594238  |                 1.0                  |            1.0            |                 1.0                 |             1.0             |                   1.0                   |               1.0               |                  1.0                  |               1.0                |                1.0                 |                      1.0                       |        0.8571000099182129         |  0.8571000099182129  |          1.0           |           1.0            |
| 1 |          gpt-4-0613          |  0.916700005531311  |  0.916700005531311  |         1.0         |       0.8125        | 0.8571000099182129  |                 1.0                  |            1.0            |                 1.0                 |             1.0             |                   1.0                   |        0.666700005531311        |                  1.0                  |               1.0                |                1.0                 |                      0.0                       |                1.0                |         0.75         |   0.7142999768257141   |           1.0            |
| 6 |    codellama-34b-instruct    | 0.8865000009536743  | 0.8865000009536743  | 0.8776000142097473  | 0.7894999980926514  | 0.9629999995231628  |          0.833299994468689           |    0.8461999893188477     |          0.666700005531311          |             1.0             |                   1.0                   |              0.75               |                  0.5                  |               1.0                |                1.0                 |               0.6000000238418579               |                1.0                |         1.0          |         0.875          |           1.0            |
| 8 |      gpt-3.5-turbo-1106      | 0.8675000071525574  | 0.8675000071525574  |       0.9375        | 0.8399999737739563  |  0.807699978351593  |                 1.0                  |           0.875           |          0.833299994468689          |             1.0             |                   1.0                   |               1.0               |          0.7142999768257141           |               0.75               |         0.800000011920929          |                      1.0                       |        0.8571000099182129         |  0.571399986743927   |   0.8571000099182129   |           1.0            |
| 2 | deepseek-coder-6.7b-instruct | 0.8066999912261963  | 0.8066999912261963  | 0.8260999917984009  | 0.8205000162124634  | 0.7646999955177307  |                 1.0                  |    0.6000000238418579     |          0.800000011920929          |            0.75             |                   1.0                   |               1.0               |           0.833299994468689           |               0.5                |         0.800000011920929          |               0.8888999819755554               |         0.800000011920929         |  0.833299994468689   |          0.75          |           0.5            |
| 3 | deepseek-coder-33b-instruct  |  0.78329998254776   |  0.78329998254776   | 0.7825999855995178  |  0.833299994468689  |  0.692300021648407  |          0.6000000238418579          |            0.5            |                 1.0                 |             1.0             |            0.800000011920929            |              0.75               |           0.833299994468689           |               1.0                |         0.800000011920929          |               0.800000011920929                |         0.833299994468689         |         0.25         |          1.0           |           1.0            |
| 0 |    codellama-13b-instruct    | 0.6912000179290771  | 0.6912000179290771  | 0.7390999794006348  |  0.583299994468689  |  0.761900007724762  |                 1.0                  |     0.800000011920929     |                 1.0                 |     0.6000000238418579      |                   0.5                   |              0.25               |          0.33329999446868896          |        0.833299994468689         |                1.0                 |               0.666700005531311                |                1.0                |  0.8571000099182129  |   0.4000000059604645   |    0.833299994468689     |
| 9 |    codellama-7b-instruct     | 0.6721000075340271  | 0.6721000075340271  | 0.7599999904632568  | 0.41179999709129333 | 0.7894999980926514  |          0.6000000238418579          |           0.75            |          0.800000011920929          |      0.833299994468689      |            0.800000011920929            |              0.75               |                  0.0                  |               0.0                |         0.4000000059604645         |               0.666700005531311                |         0.666700005531311         |  0.833299994468689   |          1.0           |    0.666700005531311     |
| 4 | deepseek-coder-1.3b-instruct | 0.37139999866485596 | 0.37139999866485596 | 0.37929999828338623 | 0.33329999446868896 | 0.41179999709129333 |          0.1429000049829483          |    0.4000000059604645     |                0.75                 |      0.428600013256073      |           0.33329999446868896           |               0.0               |           0.428600013256073           |        0.4000000059604645        |                0.25                |                      0.5                       |                0.0                |  0.4000000059604645  |   0.6000000238418579   |    0.4000000059604645    |
+---+------------------------------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------+---------------------------+-------------------------------------+-----------------------------+-----------------------------------------+---------------------------------+---------------------------------------+----------------------------------+------------------------------------+------------------------------------------------+-----------------------------------+----------------------+------------------------+--------------------------+
